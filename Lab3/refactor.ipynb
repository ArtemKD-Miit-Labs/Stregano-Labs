{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ab04b3",
   "metadata": {},
   "source": [
    "## Используемые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e744e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "from enum import Enum\n",
    "import cv2\n",
    "from PIL import Image, ImageChops\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Tuple, Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5abd28d",
   "metadata": {},
   "source": [
    "## Получение выбранного канала изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorSpaceType(Enum):\n",
    "    RGB = 'RGB'\n",
    "    YCrCb = 'YCrCb'\n",
    "\n",
    "class SubbandType(Enum):\n",
    "    LL = \"LL\"\n",
    "    LH = \"LH\"\n",
    "    HL = \"HL\"\n",
    "    HH = \"HH\"\n",
    "\n",
    "def get_image_channels(image_path: str, color_space: ColorSpaceType):\n",
    "    if color_space is ColorSpaceType.RGB:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        return {\n",
    "            'color_space': color_space,\n",
    "            'channels': img_array\n",
    "        }\n",
    "    \n",
    "    elif color_space is ColorSpaceType.YCrCb:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_array = np.array(img)\n",
    "        img_ycbcr = cv2.cvtColor(img_array, cv2.COLOR_RGB2YCrCb)\n",
    "\n",
    "        return {\n",
    "            'color_space': color_space,\n",
    "            'channels': img_ycbcr\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Invalid color space.')\n",
    "        \n",
    "def save_image_channels(img_data: np.ndarray, out_path: str, color_space: ColorSpaceType):\n",
    "    if color_space is ColorSpaceType.RGB:\n",
    "        Image.fromarray(img_data).save(out_path)\n",
    "        return\n",
    "    \n",
    "    elif color_space is ColorSpaceType.YCrCb:\n",
    "        cbcr_image_data = cv2.cvtColor(img_data, cv2.COLOR_YCrCb2RGB)\n",
    "        Image.fromarray(cbcr_image_data).save(out_path)\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Invalid color space.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b8047",
   "metadata": {},
   "source": [
    "## Заполнение контейнера и получение из него строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83333690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_bits(text: str) -> str:\n",
    "    # кодируем строку в UTF-8\n",
    "    data = text.encode(\"utf-8\")\n",
    "    # каждый байт превращаем в 8 бит\n",
    "    return ''.join(f\"{byte:08b}\" for byte in data)\n",
    "\n",
    "def bits_to_text(bits: str) -> str:\n",
    "    # берём только полные байты\n",
    "    bits = bits[: (len(bits) // 8) * 8]\n",
    "\n",
    "    # переводим 8-битные блоки в байты\n",
    "    bytes_arr = bytearray(\n",
    "        int(bits[i:i+8], 2)\n",
    "        for i in range(0, len(bits), 8)\n",
    "    )\n",
    "\n",
    "    # декодируем как UTF-8\n",
    "    return bytes_arr.decode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "def fill_container(container: np.ndarray[np.float64], text: str, Q: int):\n",
    "    bits = text_to_bits(text)\n",
    "    \n",
    "    if len(bits) > len(container):\n",
    "        raise ValueError(f\"Контейнер слишком мал для встраивания текста: необходимо {len(bits)}, есть {len(container)}\")\n",
    "    \n",
    "    modified_container = container.copy()\n",
    "\n",
    "    # Квантование: используем округление, чтобы симметрично работать с отриц. значениями\n",
    "    for idx, bit in enumerate(bits):\n",
    "        c = container[idx]\n",
    "        q = int(np.round(c / Q))\n",
    "        if bit == '0':\n",
    "            if q % 2 == 1:\n",
    "                q -= 1\n",
    "        else:\n",
    "            if q % 2 == 0:\n",
    "                q += 1\n",
    "        modified_container[idx] = q * Q\n",
    "\n",
    "    return modified_container, len(bits)\n",
    "\n",
    "def extract_container(container: np.ndarray[np.float64], text_length: int, Q: int) -> str:\n",
    "    data_bits = ''\n",
    "    for i in range(0, text_length):\n",
    "        c = container[i]\n",
    "        q = int(np.round(c / Q))\n",
    "        data_bits += '1' if (q % 2 == 1) else '0'\n",
    "\n",
    "    return bits_to_text(data_bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210f3fb",
   "metadata": {},
   "source": [
    "### Метод 1 (Выбор наиболее больших коэффициентов по убыванию)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_container_topk(container: np.ndarray[np.float64], text: str, Q: int):\n",
    "    bits = text_to_bits(text)\n",
    "    N = len(bits)\n",
    "\n",
    "    if N > len(container):\n",
    "        raise ValueError(\"Не хватает коэффициентов для Top-K\")\n",
    "\n",
    "    modified = container.copy()\n",
    "\n",
    "    # Индексы отсортированы по |c|\n",
    "    sorted_indices = np.argsort(np.abs(container))[::-1]\n",
    "    embed_indices = sorted_indices[:N]\n",
    "\n",
    "    for bit, idx in zip(bits, embed_indices):\n",
    "        c = container[idx]\n",
    "        q = int(np.round(c / Q))\n",
    "        if bit == '0':\n",
    "            if q % 2 == 1: q -= 1\n",
    "        else:\n",
    "            if q % 2 == 0: q += 1\n",
    "        modified[idx] = q * Q\n",
    "\n",
    "    return modified, N\n",
    "\n",
    "def extract_container_topk(container: np.ndarray[np.float64], text_length: int, Q: int):\n",
    "    sorted_indices = np.argsort(np.abs(container))[::-1]\n",
    "    extract_indices = sorted_indices[:text_length]\n",
    "\n",
    "    bits = ''\n",
    "    for idx in extract_indices:\n",
    "        c = container[idx]\n",
    "        q = int(np.round(c / Q))\n",
    "        bits += '1' if (q % 2 == 1) else '0'\n",
    "\n",
    "    return bits_to_text(bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74f008",
   "metadata": {},
   "source": [
    "### Метод 2 (Выбор коэффициентов по порогу в ручную)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472781f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_container_threshold(container: np.ndarray[np.float64], text: str, Q: int, T: float):\n",
    "    bits = text_to_bits(text)\n",
    "\n",
    "    # выбираем коэффициенты выше порога\n",
    "    candidate_indices = np.where(np.abs(container) >= T)[0]\n",
    "\n",
    "    print(f'max: {np.max(np.abs(container))}')\n",
    "\n",
    "    print(f\"Коэффициентов ≥ T: {len(candidate_indices)}, необходимо для встраивания: {len(bits)}\")\n",
    "\n",
    "    if len(candidate_indices) < len(bits):\n",
    "        raise ValueError(\"Недостаточно коэффициентов ≥ T\")\n",
    "\n",
    "    modified = container.copy()\n",
    "\n",
    "    for bit, idx in zip(bits, candidate_indices):\n",
    "        c = container[idx]\n",
    "        q = int(np.round(c / Q))\n",
    "        if bit == '0':\n",
    "            if q % 2 == 1: q -= 1\n",
    "        else:\n",
    "            if q % 2 == 0: q += 1\n",
    "        modified[idx] = q * Q\n",
    "\n",
    "    return modified, len(bits)\n",
    "\n",
    "def extract_container_threshold(container: np.ndarray[np.float64], text_length: int, Q: int, T: float):\n",
    "    candidate_indices = np.where(np.abs(container) >= T)[0]\n",
    "\n",
    "    print(f'max: {np.max(np.abs(container))}')\n",
    "\n",
    "    print(f\"Коэффициентов ≥ T: {len(candidate_indices)}, необходимо для извлечения: {text_length}\")\n",
    "\n",
    "    if len(candidate_indices) < text_length:\n",
    "        raise ValueError(\"Недостаточно коэффициентов ≥ T для извлечения\")\n",
    "\n",
    "    bits = ''\n",
    "    for idx in candidate_indices[:text_length]:\n",
    "        c = container[idx]\n",
    "        q = int(np.round(c / Q))\n",
    "        bits += '1' if (q % 2 == 1) else '0'\n",
    "\n",
    "    return bits_to_text(bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de47e2",
   "metadata": {},
   "source": [
    "## Анализ изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ea005",
   "metadata": {},
   "source": [
    "### Выделение отличий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_diff(img1: np.ndarray, img2: np.ndarray, amplify: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Создаёт diff двух изображений с усилением различий.\n",
    "\n",
    "    amplify — множитель, чтобы лучше выделять слабые различия.\n",
    "    \"\"\"\n",
    "    pil1 = Image.fromarray(img1)\n",
    "    pil2 = Image.fromarray(img2)\n",
    "    diff = ImageChops.difference(pil1, pil2)\n",
    "\n",
    "    # Усиливаем различия\n",
    "    diff = diff.point(lambda p: min(255, p * amplify))\n",
    "\n",
    "    return np.array(diff)\n",
    "\n",
    "\n",
    "def image_mask(img1: np.ndarray, img2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Создаёт бинарную маску различий (красные пиксели — есть разница).\n",
    "    \"\"\"\n",
    "    mask = np.any(img1 != img2, axis=-1)\n",
    "\n",
    "    heatmap = np.zeros_like(img1)\n",
    "    heatmap[mask] = [255, 0, 0]\n",
    "\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b6afc",
   "metadata": {},
   "source": [
    "### Вычисление PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5bdf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(img1: np.ndarray, img2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Простой PSNR для RGB или grayscale.\n",
    "    \"\"\"\n",
    "    if img1.shape != img2.shape:\n",
    "        raise ValueError(f\"Размеры не совпадают: {img1.shape} != {img2.shape}\")\n",
    "\n",
    "    mse = np.mean((img1.astype(float) - img2.astype(float)) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "\n",
    "    return 10 * np.log10((255.0 ** 2) / mse)\n",
    "\n",
    "\n",
    "def calculate_psnr_detailed(img1: np.ndarray, img2: np.ndarray) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    PSNR по каналам + средний PSNR.\n",
    "    \"\"\"\n",
    "    if img1.shape != img2.shape:\n",
    "        raise ValueError(\"Размеры изображений не совпадают\")\n",
    "\n",
    "    if img1.ndim == 2:\n",
    "        # 1 канал\n",
    "        mse = np.mean((img1.astype(float) - img2.astype(float)) ** 2)\n",
    "        psnr = float('inf') if mse == 0 else 10 * np.log10((255.0 ** 2) / mse)\n",
    "        return {\"psnr\": psnr, \"mse\": mse}\n",
    "\n",
    "    results = {}\n",
    "    names = [\"R\", \"G\", \"B\"]\n",
    "\n",
    "    psnrs = []\n",
    "    mses = []\n",
    "\n",
    "    for i, ch in enumerate(names):\n",
    "        c1 = img1[:, :, i].astype(float)\n",
    "        c2 = img2[:, :, i].astype(float)\n",
    "\n",
    "        mse = np.mean((c1 - c2) ** 2)\n",
    "        psnr = float('inf') if mse == 0 else 10 * np.log10((255.0 ** 2) / mse)\n",
    "\n",
    "        results[f\"psnr_{ch}\"] = psnr\n",
    "        results[f\"mse_{ch}\"] = mse\n",
    "\n",
    "        psnrs.append(psnr)\n",
    "        mses.append(mse)\n",
    "\n",
    "    results[\"psnr_avg\"] = np.mean(psnrs)\n",
    "    results[\"mse_avg\"] = np.mean(mses)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bb4cdf",
   "metadata": {},
   "source": [
    "### Полный анализ изображений и визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6de32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_comparison(\n",
    "        original: np.ndarray,\n",
    "        modified: np.ndarray,\n",
    "        diff: np.ndarray,\n",
    "        mask: np.ndarray,\n",
    "        figsize: Tuple[int, int] = (16, 8)\n",
    "):\n",
    "    \"\"\"\n",
    "    Рисует 4 изображения: исходное, модифицированное, diff и маску различий.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(original)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.title(\"Modified\")\n",
    "    plt.imshow(modified)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.title(\"Diff (amplified)\")\n",
    "    plt.imshow(diff)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.title(\"Difference Mask\")\n",
    "    plt.imshow(mask)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_comparison_v2(\n",
    "        original: np.ndarray,\n",
    "        modified: np.ndarray,\n",
    "        diff: np.ndarray,\n",
    "        mask: np.ndarray,\n",
    "        figsize: Tuple[int, int] = (12, 8)\n",
    "):\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(original)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Modified\")\n",
    "    plt.imshow(modified)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Diff (amplified)\")\n",
    "    plt.imshow(diff)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Difference Mask\")\n",
    "    plt.imshow(mask)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(\"comparison.png\")\n",
    "\n",
    "\n",
    "def analyze_images(path1: str, path2: str, amplify: int = 10) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Полный анализ двух изображений:\n",
    "    - diff\n",
    "    - маска различий\n",
    "    - PSNR\n",
    "    - PSNR по каналам\n",
    "\n",
    "    Возвращает словарь с результатами.\n",
    "    \"\"\"\n",
    "    img1 = Image.open(path1).convert(\"RGB\")\n",
    "    img2 = Image.open(path2).convert(\"RGB\")\n",
    "    img_data1 = np.array(img1)\n",
    "    img_data2 = np.array(img2)\n",
    "\n",
    "    diff = image_diff(img_data1, img_data2, amplify)\n",
    "    mask = image_mask(img_data1, img_data2)\n",
    "\n",
    "    psnr = calculate_psnr(img_data1, img_data2)\n",
    "    psnr_detailed = calculate_psnr_detailed(img_data1, img_data2)\n",
    "\n",
    "    visualize_comparison_v2(img_data1, img_data2, diff, mask)\n",
    "\n",
    "    Image.fromarray(diff).save(\"diff.png\")\n",
    "    Image.fromarray(mask).save(\"mask.png\")\n",
    "\n",
    "    return {\n",
    "        \"psnr\": psnr,\n",
    "        \"psnr_detailed\": psnr_detailed,\n",
    "        \"diff\": diff,\n",
    "        \"mask\": mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e650d62",
   "metadata": {},
   "source": [
    "## Анализ встроенной информации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10705af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_percentage_chars(original: str, extracted: str) -> float:\n",
    "    \"\"\"\n",
    "    Возвращает процент символов, которые отличаются между original и extracted\n",
    "    \"\"\"\n",
    "    # берём длину меньшей строки\n",
    "    length = max(len(original), len(extracted))\n",
    "    if length == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # считаем несовпадающие позиции\n",
    "    mismatches = 0\n",
    "    for i in range(length):\n",
    "        c1 = original[i] if i < len(original) else None\n",
    "        c2 = extracted[i] if i < len(extracted) else None\n",
    "        if c1 != c2:\n",
    "            mismatches += 1\n",
    "    \n",
    "    return 100.0 * mismatches / length\n",
    "\n",
    "def compare_strings(str1, str2):\n",
    "    \"\"\"Сравнивает две строки и показывает различия\"\"\"\n",
    "    if len(str1) != len(str2):\n",
    "        print(f\"Длины разные: {len(str1)} vs {len(str2)}\")\n",
    "    \n",
    "    min_len = min(len(str1), len(str2))\n",
    "    differences = []\n",
    "    \n",
    "    for i in range(min_len):\n",
    "        if str1[i] != str2[i]:\n",
    "            differences.append((i, str1[i], str2[i]))\n",
    "    \n",
    "    if differences:\n",
    "        print(\"Найдены различия:\")\n",
    "        for pos, char1, char2 in differences:\n",
    "            print(f\"  Позиция {pos}: '{char1}' vs '{char2}'\")\n",
    "    else:\n",
    "        print(\"Строки идентичны (в пределах общей длины)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e48d30",
   "metadata": {},
   "source": [
    "## Функции встраивания текста в изображение и получение теста из изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(image_path: str, out_path: str, embedded_text: str, Q: int, color_space: ColorSpaceType = ColorSpaceType.RGB, target_subband: str = 'LL', channel: int = 0) -> dict:\n",
    "    # 1. Получаем выбранный канал изображения\n",
    "    img_data = get_image_channels(image_path, color_space)\n",
    "    channel_data = img_data['channels'][:, :, channel].astype(np.float64)\n",
    "\n",
    "    # 2. Применяем к каналу DWT (используем symmetric для более стабильного поведения)\n",
    "    wt_type = 'haar'\n",
    "    wt_mode = 'symmetric'\n",
    "    \n",
    "    LL, (LH, HL, HH) = pywt.dwt2(channel_data, wt_type, mode=wt_mode)\n",
    "    coeffs_dict = {\n",
    "        'LL': LL,\n",
    "        'LH': LH,\n",
    "        'HL': HL,\n",
    "        'HH': HH\n",
    "    }\n",
    "\n",
    "    # 3. Берем выбранную подполосу и приводим ее к одномерному массиву дл удобства\n",
    "    selected_subband: np.ndarray[np.float64] = coeffs_dict[target_subband]\n",
    "    container = selected_subband.flatten()\n",
    "\n",
    "    # 4. Модифициурем контейнер (одномерный массив)\n",
    "    modified_container, embedded_count = fill_container(container, embedded_text, Q)\n",
    "    # modified_container, embedded_count = fill_container_topk(container, embedded_text, Q)\n",
    "    # modified_container, embedded_count = fill_container_threshold(container, embedded_text, Q, T = 400.0)\n",
    "\n",
    "    # 5. Выполняем обратные преобразования для получения модифицированного канала\n",
    "    modied_subband = modified_container.reshape(selected_subband.shape)\n",
    "    coeffs_dict[target_subband] = modied_subband\n",
    "    modified_coeffs = (coeffs_dict['LL'], \n",
    "                           (coeffs_dict['LH'], \n",
    "                            coeffs_dict['HL'], \n",
    "                            coeffs_dict['HH']))\n",
    "    modified_channel_data = pywt.idwt2(modified_coeffs, wt_type, mode=wt_mode)\n",
    "\n",
    "    # 6. Сохраняем модифицированный канал в изображении\n",
    "    img_data['channels'][:, :, channel] = modified_channel_data\n",
    "    save_image_channels(img_data['channels'], out_path, color_space)\n",
    "\n",
    "    return {\n",
    "        'image_data': img_data,\n",
    "        'selected_channel': channel,\n",
    "        'channel_data': channel_data,\n",
    "        'target_subband': target_subband,\n",
    "        'embedded_count': embedded_count,\n",
    "        'Q': Q\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(image_path: str, embedded_count: int, Q: int, color_space: ColorSpaceType = ColorSpaceType.RGB, target_subband: str = 'LL', channel: int = 0) -> dict:\n",
    "    # 1. Получаем выбранный канал изображения\n",
    "    img_data = get_image_channels(image_path, color_space)\n",
    "    channel_data = img_data['channels'][:, :, channel].astype(np.float64)\n",
    "\n",
    "    # 2. Применяем к каналу DWT (используем symmetric для более стабильного поведения)\n",
    "    wt_type = 'haar'\n",
    "    wt_mode = 'symmetric'\n",
    "    \n",
    "    LL, (LH, HL, HH) = pywt.dwt2(channel_data, wt_type, mode=wt_mode)\n",
    "    coeffs_dict = {\n",
    "        'LL': LL,\n",
    "        'LH': LH,\n",
    "        'HL': HL,\n",
    "        'HH': HH\n",
    "    }\n",
    "\n",
    "    # 3. Берем выбранную подполосу и приводим ее к одномерному массиву дл удобства\n",
    "    selected_subband: np.ndarray[np.float64] = coeffs_dict[target_subband]\n",
    "    container = selected_subband.flatten()\n",
    "\n",
    "    # 4. Извлекаем текст из контейнера    \n",
    "    embedded_text = extract_container(container, embedded_count, Q)\n",
    "    # embedded_text = extract_container_topk(container, embedded_count, Q)\n",
    "    # embedded_text = extract_container_threshold(container, embedded_count, Q, T = 400.0)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'image_data': img_data,\n",
    "        'selected_channel': channel,\n",
    "        'channel_data': channel_data,\n",
    "        'target_subband': target_subband,\n",
    "        'extracted_text': embedded_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c2a20",
   "metadata": {},
   "source": [
    "## Демонстрация работы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037fbd69",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_img_path = 'img/marsik-960x1280-cleared.png'\n",
    "embedded_img_path = 'embedded/marsik-960x1280-cleared-embedded.png'\n",
    "\n",
    "# used_img_path = 'img/marsik-960x1280.png'\n",
    "# embedded_img_path = 'embedded/marsik-960x1280-embedded.png'\n",
    "\n",
    "# used_img_path = 'img/marsik-960x1280.jpg'\n",
    "# embedded_img_path = 'embedded/marsik-960x1280-embedded.jpg'\n",
    "\n",
    "# used_img_path = 'img/marsik-600x800.png'\n",
    "# embedded_img_path = 'embedded/marsik-600x800-embedded.png'\n",
    "\n",
    "# used_img_path = 'img/marsik-300x400.png'\n",
    "# embedded_img_path = 'embedded/marsik-300x400-embedded.png'\n",
    "\n",
    "# used_img_path = 'img/marsik-150x200.png'\n",
    "# embedded_img_path = 'embedded/marsik-150x200-embedded.png'\n",
    "\n",
    "# used_img_path = 'img/cat.jpg'\n",
    "# embedded_img_path = 'embedded/cat-embedded.jpg'\n",
    "\n",
    "# used_img_path = 'img/cat-cleared.jpg'\n",
    "# embedded_img_path = 'embedded/cat-cleared-embedded.jpg'\n",
    "\n",
    "# used_img_path = 'img/forest.jpg'\n",
    "# embedded_img_path = 'embedded/forest-embedded.jpg'\n",
    "\n",
    "secret_string = \"Silence in an era of noise: How to find yourself in a world that never stops Our world is immersed in a continuous, intrusive hum. This is not just the physical noise of megacities, but a fundamental information and social backdrop that has become our new habitat. We wake up to the vibration of our smartphones, scroll through our news feeds at breakfast, and are immersed in a whirlwind of notifications, messaging apps, and endless online meetings at work. In the evening, as we try to relax, we unconsciously scroll through social media, consuming the carefully curated lives of others. This permanent digital noise creates the illusion of hyper-connection, but paradoxically leads to deep loneliness and distraction. We know more about the world, but less about ourselves. We have thousands of \\\"friends,\\\" but sometimes we don't have anyone to share our true sadness or joy with.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a485f5bb",
   "metadata": {},
   "source": [
    "### Встраивание и получения встроенного изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_result = embed_text(\n",
    "    image_path=used_img_path,\n",
    "    out_path=embedded_img_path,\n",
    "    Q=7,\n",
    "    embedded_text=secret_string,\n",
    "    color_space=ColorSpaceType.YCrCb,\n",
    "    target_subband='LL',\n",
    "    channel=0\n",
    ")\n",
    "\n",
    "print(f'Встроено битов: {embedded_result[\"embedded_count\"]}')\n",
    "\n",
    "extract_result = extract_text(\n",
    "    image_path=embedded_img_path,\n",
    "    embedded_count=embedded_result['embedded_count'],\n",
    "    Q=embedded_result['Q'],\n",
    "    color_space=embedded_result['image_data']['color_space'],\n",
    "    target_subband=embedded_result['target_subband'],\n",
    "    channel=embedded_result['selected_channel']\n",
    ")\n",
    "\n",
    "print(f'Извлечённый текст: {extract_result[\"extracted_text\"]}')\n",
    "print(f'Извлечено битов: {len(extract_result[\"extracted_text\"]) * 8}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e638ca",
   "metadata": {},
   "source": [
    "### Анализ результатов встраивания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48652bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = analyze_images(\n",
    "    used_img_path,\n",
    "    embedded_img_path,\n",
    "    amplify=10\n",
    ")\n",
    "\n",
    "print(\"PSNR:\", result[\"psnr\"])\n",
    "# print(result[\"psnr_detailed\"])\n",
    "\n",
    "loss_percent = loss_percentage_chars(secret_string, extract_result[\"extracted_text\"])\n",
    "print(f\"Процент потерянных символов: {loss_percent:.2f}%\")\n",
    "compare_strings(secret_string, extract_result[\"extracted_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stegano-labs (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
