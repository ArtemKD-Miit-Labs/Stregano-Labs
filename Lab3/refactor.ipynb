{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ab04b3",
   "metadata": {},
   "source": [
    "### Используемые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e744e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "from enum import Enum\n",
    "import cv2\n",
    "from PIL import Image, ImageChops\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Tuple, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorSpaceType(Enum):\n",
    "    RGB = 'RGB'\n",
    "    YCrCb = 'YCrCb'\n",
    "\n",
    "class SubbandType(Enum):\n",
    "    LL = \"LL\"\n",
    "    LH = \"LH\"\n",
    "    HL = \"HL\"\n",
    "    HH = \"HH\"\n",
    "\n",
    "def get_image_channels(image_path: str, color_space: ColorSpaceType):\n",
    "    if color_space is ColorSpaceType.RGB:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        return {\n",
    "            'color_space': color_space,\n",
    "            'channels': img_array\n",
    "        }\n",
    "    \n",
    "    elif color_space is ColorSpaceType.YCrCb:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_array = np.array(img)\n",
    "        img_ycbcr = cv2.cvtColor(img_array, cv2.COLOR_RGB2YCrCb)\n",
    "\n",
    "        return {\n",
    "            'color_space': color_space,\n",
    "            'channels': img_ycbcr\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Invalid color space.')\n",
    "        \n",
    "def save_image_channels(img_data: np.ndarray, out_path: str, color_space: ColorSpaceType):\n",
    "    if color_space is ColorSpaceType.RGB:\n",
    "        Image.fromarray(img_data).save(out_path)\n",
    "        return\n",
    "    \n",
    "    elif color_space is ColorSpaceType.YCrCb:\n",
    "        cbcr_image_data = cv2.cvtColor(img_data, cv2.COLOR_YCrCb2RGB)\n",
    "        Image.fromarray(cbcr_image_data).save(out_path)\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Invalid color space.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de47e2",
   "metadata": {},
   "source": [
    "## Анализ изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ea005",
   "metadata": {},
   "source": [
    "### Выделение отличий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_diff(img1: np.ndarray, img2: np.ndarray, amplify: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Создаёт diff двух изображений с усилением различий.\n",
    "\n",
    "    amplify — множитель, чтобы лучше выделять слабые различия.\n",
    "    \"\"\"\n",
    "    pil1 = Image.fromarray(img1)\n",
    "    pil2 = Image.fromarray(img2)\n",
    "    diff = ImageChops.difference(pil1, pil2)\n",
    "\n",
    "    # Усиливаем различия\n",
    "    diff = diff.point(lambda p: min(255, p * amplify))\n",
    "\n",
    "    return np.array(diff)\n",
    "\n",
    "\n",
    "def image_mask(img1: np.ndarray, img2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Создаёт бинарную маску различий (красные пиксели — есть разница).\n",
    "    \"\"\"\n",
    "    mask = np.any(img1 != img2, axis=-1)\n",
    "\n",
    "    heatmap = np.zeros_like(img1)\n",
    "    heatmap[mask] = [255, 0, 0]\n",
    "\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b6afc",
   "metadata": {},
   "source": [
    "### Вычисление PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5bdf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(img1: np.ndarray, img2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Простой PSNR для RGB или grayscale.\n",
    "    \"\"\"\n",
    "    if img1.shape != img2.shape:\n",
    "        raise ValueError(f\"Размеры не совпадают: {img1.shape} != {img2.shape}\")\n",
    "\n",
    "    mse = np.mean((img1.astype(float) - img2.astype(float)) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "\n",
    "    return 10 * np.log10((255.0 ** 2) / mse)\n",
    "\n",
    "\n",
    "def calculate_psnr_detailed(img1: np.ndarray, img2: np.ndarray) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    PSNR по каналам + средний PSNR.\n",
    "    \"\"\"\n",
    "    if img1.shape != img2.shape:\n",
    "        raise ValueError(\"Размеры изображений не совпадают\")\n",
    "\n",
    "    if img1.ndim == 2:\n",
    "        # 1 канал\n",
    "        mse = np.mean((img1.astype(float) - img2.astype(float)) ** 2)\n",
    "        psnr = float('inf') if mse == 0 else 10 * np.log10((255.0 ** 2) / mse)\n",
    "        return {\"psnr\": psnr, \"mse\": mse}\n",
    "\n",
    "    results = {}\n",
    "    names = [\"R\", \"G\", \"B\"]\n",
    "\n",
    "    psnrs = []\n",
    "    mses = []\n",
    "\n",
    "    for i, ch in enumerate(names):\n",
    "        c1 = img1[:, :, i].astype(float)\n",
    "        c2 = img2[:, :, i].astype(float)\n",
    "\n",
    "        mse = np.mean((c1 - c2) ** 2)\n",
    "        psnr = float('inf') if mse == 0 else 10 * np.log10((255.0 ** 2) / mse)\n",
    "\n",
    "        results[f\"psnr_{ch}\"] = psnr\n",
    "        results[f\"mse_{ch}\"] = mse\n",
    "\n",
    "        psnrs.append(psnr)\n",
    "        mses.append(mse)\n",
    "\n",
    "    results[\"psnr_avg\"] = np.mean(psnrs)\n",
    "    results[\"mse_avg\"] = np.mean(mses)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bb4cdf",
   "metadata": {},
   "source": [
    "### Полный анализ изображений и визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6de32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_comparison(\n",
    "        original: np.ndarray,\n",
    "        modified: np.ndarray,\n",
    "        diff: np.ndarray,\n",
    "        mask: np.ndarray,\n",
    "        figsize: Tuple[int, int] = (16, 8)\n",
    "):\n",
    "    \"\"\"\n",
    "    Рисует 4 изображения: исходное, модифицированное, diff и маску различий.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(original)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.title(\"Modified\")\n",
    "    plt.imshow(modified)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.title(\"Diff (amplified)\")\n",
    "    plt.imshow(diff)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.title(\"Difference Mask\")\n",
    "    plt.imshow(mask)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def analyze_images(path1: str, path2: str, amplify: int = 10) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Полный анализ двух изображений:\n",
    "    - diff\n",
    "    - маска различий\n",
    "    - PSNR\n",
    "    - PSNR по каналам\n",
    "\n",
    "    Возвращает словарь с результатами.\n",
    "    \"\"\"\n",
    "    img1 = Image.open(path1).convert(\"RGB\")\n",
    "    img2 = Image.open(path2).convert(\"RGB\")\n",
    "    img_data1 = np.array(img1)\n",
    "    img_data2 = np.array(img2)\n",
    "\n",
    "    diff = image_diff(img_data1, img_data2, amplify)\n",
    "    mask = image_mask(img_data1, img_data2)\n",
    "\n",
    "    psnr = calculate_psnr(img_data1, img_data2)\n",
    "    psnr_detailed = calculate_psnr_detailed(img_data1, img_data2)\n",
    "\n",
    "    visualize_comparison(img_data1, img_data2, diff, mask)\n",
    "\n",
    "    return {\n",
    "        \"psnr\": psnr,\n",
    "        \"psnr_detailed\": psnr_detailed,\n",
    "        \"diff\": diff,\n",
    "        \"mask\": mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e48d30",
   "metadata": {},
   "source": [
    "## Функции встраивания текста в изображение и получение теста из изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(image_path: str, out_path: str, text: str, color_space: ColorSpaceType = ColorSpaceType.RGB, target_subband: str = 'LL', channel: int = 0) -> dict:\n",
    "    # 1. Получаем выбранный канал изображения\n",
    "    img_data = get_image_channels(image_path, color_space)\n",
    "    channel_data = img_data['channels'][:, :, channel].astype(np.float64)\n",
    "\n",
    "    # 2. Применяем к каналу DWT (используем symmetric для более стабильного поведения)\n",
    "    wt_type = 'haar'\n",
    "    wt_mode = 'symmetric'\n",
    "    \n",
    "    LL, (LH, HL, HH) = pywt.dwt2(channel_data, wt_type, mode=wt_mode)\n",
    "    coeffs_dict = {\n",
    "        'LL': LL,\n",
    "        'LH': LH,\n",
    "        'HL': HL,\n",
    "        'HH': HH\n",
    "    }\n",
    "\n",
    "    # 3. Берем выбранную подполосу и приводим ее к одномерному массиву дл удобства\n",
    "    selected_subband: np.ndarray[np.float64] = coeffs_dict[target_subband]\n",
    "    subband = selected_subband.flatten()\n",
    "\n",
    "    # 4. Модифициурем контейнер (одномерный массив)\n",
    "    #\n",
    "\n",
    "    # 5. Выполняем обратные преобразования для получения модифицированного канала\n",
    "    modied_subband = subband.reshape(selected_subband.shape)\n",
    "    coeffs_dict[target_subband] = modied_subband\n",
    "    modified_coeffs = (coeffs_dict['LL'], \n",
    "                           (coeffs_dict['LH'], \n",
    "                            coeffs_dict['HL'], \n",
    "                            coeffs_dict['HH']))\n",
    "    modified_channel_data = pywt.idwt2(modified_coeffs, wt_type, mode=wt_mode)\n",
    "\n",
    "    # 6. Сохраняем модифицированный канал в изображении\n",
    "    img_data['channels'][:, :, channel] = modified_channel_data\n",
    "    save_image_channels(img_data['channels'], out_path, color_space)\n",
    "\n",
    "    return {\n",
    "        'image_data': img_data,\n",
    "        'selected_channel': channel,\n",
    "        'channel_data': channel_data,\n",
    "        'target_subband': target_subband\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(image_path: str, color_space: ColorSpaceType = ColorSpaceType.RGB, target_subband: str = 'LL', channel: int = 0) -> dict:\n",
    "    img_data = get_image_channels(image_path, color_space)\n",
    "    channel_data = img_data['channels'][:, :, channel].astype(np.float64)\n",
    "\n",
    "    return {\n",
    "        'image_data': img_data,\n",
    "        'selected_channel': channel,\n",
    "        'channel_data': channel_data,\n",
    "        'target_subband': target_subband,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c2a20",
   "metadata": {},
   "source": [
    "## Демонстрация работы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037fbd69",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_img_path = 'img/marsik-150x200.png'\n",
    "# embedded_img_path = 'embedded/marsik-150x200-embedded.png'\n",
    "\n",
    "used_img_path = 'img/marsik-960x1280.png'\n",
    "embedded_img_path = 'embedded/marsik-960x1280-embedded.png'\n",
    "\n",
    "secret_string = \"Silence in an era of noise: How to find yourself in a world that never stops Our world is immersed in a continuous, intrusive hum. This is not just the physical noise of megacities, but a fundamental information and social backdrop that has become our new habitat. We wake up to the vibration of our smartphones, scroll through our news feeds at breakfast, and are immersed in a whirlwind of notifications, messaging apps, and endless online meetings at work. In the evening, as we try to relax, we unconsciously scroll through social media, consuming the carefully curated lives of others. This permanent digital noise creates the illusion of hyper-connection, but paradoxically leads to deep loneliness and distraction. We know more about the world, but less about ourselves. We have thousands of \\\"friends,\\\" but sometimes we don't have anyone to share our true sadness or joy with.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a485f5bb",
   "metadata": {},
   "source": [
    "### Встраивание и получения встроенного изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_result = embed_text(\n",
    "    used_img_path,\n",
    "    embedded_img_path,\n",
    "    secret_string,\n",
    "    color_space=ColorSpaceType.YCrCb,\n",
    "    target_subband='HL',\n",
    "    channel=0\n",
    ")\n",
    "\n",
    "extract_result = extract_text(\n",
    "    embedded_img_path,\n",
    "    color_space=embedded_result['image_data']['color_space'],\n",
    "    target_subband=embedded_result['target_subband'],\n",
    "    channel=embedded_result['selected_channel']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e638ca",
   "metadata": {},
   "source": [
    "### Анализ результатов встраивания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48652bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = analyze_images(\n",
    "    used_img_path,\n",
    "    embedded_img_path,\n",
    "    amplify=5\n",
    ")\n",
    "\n",
    "print(\"PSNR:\", result[\"psnr\"])\n",
    "print(result[\"psnr_detailed\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stregano-Labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
